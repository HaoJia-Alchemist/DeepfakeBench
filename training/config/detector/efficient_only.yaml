# log dir 
log_dir: /home/jh/disk1/logs/DeepfakeBench/dsmsnlc

# model setting
model:
  name: efficient_only_detector   # model name
  backbone: efficientnet-b4  # backbone name
  noise_extractor: # Noise extractor definition
    name: srm  # Noise extractor name: noise_print++, srm, bayarconv
    np_weights: /home/jh/disk/pretrained/DeepfakeDetection/dncnn.pth  # Noise Print++ weights path
    out_channels: 3 # Noise Channels
  dcam: # Dual channels attention module definition
    name: dcbam  # Dual channels attention module name: dcbam, dca
  multi_scale: [ b1, b3, b7 ] # Multi-scale definition
  patch_size: [ 16, 4, 1 ] # Multi-scale definition
  checkpoints: null # Checkpoints of network
  mid_dim: 256 # Model mid_dim
  num_classes: 2 # Model class num
  drop_rate: 0.4 # Model drop out rate

# dataset
all_dataset: [ FaceForensics++, FF-F2F, FF-DF, FF-FS, FF-NT, FaceShifter, DeepFakeDetection, Celeb-DF-v1, Celeb-DF-v2, DFDCP, DFDC, DeeperForensics-1.0, UADFV ]
train_dataset: [ FF-NT ]
test_dataset: [ FaceForensics++, FF-F2F, FF-DF, FF-FS, FF-NT ]
dataset_json_folder: '/home/jh/disk/datasets/deepfake/dataset_json'
save_ckpt: true   # whether to save checkpoint
save_feat: false   # whether to save features
save_data_dict: false # whether to save data dict

compression: c23  # compression-level for videos
train_batchSize: 15   # training batch size
test_batchSize: 50   # test batch size
workers: 8   # number of data loading workers
frame_num: { 'train': 32, 'test': 32 }   # number of frames to use per video in training and testing
resolution: 384   # resolution of output image to network
balance_data: true   # whether to balance the number of real and fake videos in training data
with_mask: true   # whether to include mask information in the input
with_landmark: false   # whether to include facial landmark information in the input

# label settings
label_dict:
  # DFD
  DFD_fake: 1
  DFD_real: 0
  # FF++ + FaceShifter(FF-real+FF-FH)
  FF-SH: 1
  FF-F2F: 1
  FF-DF: 1
  FF-FS: 1
  FF-NT: 1
  FF-FH: 1
  FF-real: 0
  # CelebDF
  CelebDFv1_real: 0
  CelebDFv1_fake: 1
  CelebDFv2_real: 0
  CelebDFv2_fake: 1
  # DFDCP
  DFDCP_Real: 0
  DFDCP_FakeA: 1
  DFDCP_FakeB: 1
  # DFDC
  DFDC_Fake: 1
  DFDC_Real: 0
  # DeeperForensics-1.0
  DF_fake: 1
  DF_real: 0
  # UADFV
  UADFV_Fake: 1
  UADFV_Real: 0



# data augmentation
use_data_augmentation: false  # Add this flag to enable/disable data augmentation
data_aug:
  flip_prob: 0.5
  rotate_prob: 0.5
  rotate_limit: [ -10, 10 ]
  blur_prob: 0.5
  blur_limit: [ 3, 7 ]
  brightness_prob: 0.5
  brightness_limit: [ -0.1, 0.1 ]
  contrast_limit: [ -0.1, 0.1 ]
  quality_lower: 40
  quality_upper: 100

# mean and std for normalization
mean: [0.485, 0.456, 0.406]
std: [0.229, 0.224, 0.225]

# optimizer config
optimizer:
  # choose between 'adam', 'sgd' and 'adamW'
  type: adamW
  adam:
    lr: 0.0002  # learning rate
    beta1: 0.9  # beta1 for Adam optimizer
    beta2: 0.999 # beta2 for Adam optimizer
    eps: 0.00000001  # epsilon for Adam optimizer
    weight_decay: 0.0005  # weight decay for regularization
    amsgrad: false
  sgd:
    lr: 0.0002  # learning rate
    momentum: 0.9  # momentum for SGD optimizer
    weight_decay: 0.0005  # weight decay for regularization
  adamW:
    lr: 0.0001  # learning rate
    beta1: 0.9  # beta1 for Adam optimizer
    beta2: 0.999 # beta2 for Adam optimizer
    weight_decay: 0.000001  # weight decay for regularization

# training config
lr_scheduler: step   # learning rate scheduler
lr_step: 6000
lr_gamma: 0.5
nEpochs: 10   # number of epochs to train for
start_epoch: 0   # manual epoch number (useful for restarts)
save_epoch: 5   # interval epochs for saving models
rec_iter: 100   # interval iterations for recording
logdir: ./logs   # folder to output images and logs
manualSeed: 1234   # manual seed for random number generation

# loss function
loss_func: cross_entropy   # loss function to use
losstype: null

# metric
metric_scoring: auc   # metric for evaluation (auc, acc, eer, ap)

# cuda
gpus: [0, 1]   # number of GPUs to use
cuda: true   # whether to use CUDA acceleration
cudnn: true   # whether to use CuDNN for convolution operations
